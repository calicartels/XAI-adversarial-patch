# XAI-Adversarial-Patch

This project demonstrates the creation of an adversarial patch and its impact on a deep learning model. The patch has been tested on the ResNet34 architecture, with the target class chosen as "banana."

## Creative Component

In addition to the adversarial patch, the Fast Gradient Sign Method (FGSM) was employed to distort a separate image of a banana. The results are displayed to illustrate how FGSM attacks manipulate the input to deceive the model.

## Image, before and after FGSM Distortion.

![Original Image](how-many-calories-are-in-a-banana-1440x810.jpg)
![FGSM Distorted Image](https://github.com/calicartels/XAI-adversarial-patch/blob/main/download%20(2).png)
